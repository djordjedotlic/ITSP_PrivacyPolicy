{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sacremoses import MosesDetokenizer\n",
    "import gensim\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.sklearn_api import D2VTransformer, LsiTransformer, LdaTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "np.random.seed(1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "pol = pd.read_csv(\"Policy.csv\", engine = \"python\", names = [\"Policy\", \"Text\"])\n",
    "non_pol = pd.read_csv(\"No_Policy - Corpus.csv\", engine = \"python\", names = [\"Policy\", \"Text\"])\n",
    "df = pd.DataFrame.append(pol, non_pol)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df['Policy'].loc[df['Policy'] == -1] = 0\n",
    "df['Text_lang'] = df.apply(lambda row: detect(row['Text']), axis=1)\n",
    "df = df[df.Text_lang.isin(['en'])]\n",
    "stop_words = set(stopwords.words('english')) \n",
    "df['Text'] = df['Text'].map(preprocess)\n",
    "df = df.dropna(axis= 0)\n",
    "df = df.reset_index(drop = True)\n",
    "mdtk = MosesDetokenizer()\n",
    "df['Text'] = df['Text'].map(mdtk.detokenize)\n",
    "#data_text = df[['Text']]\n",
    "#data_text['index'] = data_text.index\n",
    "#documents = data_text\n",
    "\n",
    "\n",
    "#processed_docs = documents['Text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_x = df[['Text']].as_matrix()\n",
    "data_y = df.drop(['Text', 'Text_lang'], axis=1).as_matrix()\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=2, test_size=0.33)\n",
    "\n",
    "documents = df[['Text']]\n",
    "documents['index'] = documents.index\n",
    "\n",
    "processed_docs = documents['Text'].map(preprocess)\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_wow = pd.Series((v for v in bow_corpus))\n",
    "\n",
    "\n",
    "for train_index, test_index in stratified_split.split(data_x, data_y):\n",
    "    x_train, x_test = data_x[train_index], data_x[test_index]\n",
    "    y_train, y_test = data_y[train_index], data_y[test_index]\n",
    "    \n",
    "    common_texts_train = processed_docs[train_index]\n",
    "    common_texts_test = processed_docs[test_index]\n",
    "\n",
    "    bow_train = bow_wow[train_index].tolist()\n",
    "    bow_test = bow_wow[test_index].tolist()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "common_texts_train = common_texts_train.reset_index(drop = True).tolist()    \n",
    "common_texts_test = common_texts_test.reset_index(drop = True).tolist()        \n",
    "    \n",
    "# transform matrix of plots into lists to pass to a TfidfVectorizer\n",
    "train_x = [x[0].strip() for x in x_train.tolist()]\n",
    "test_x = [x[0].strip() for x in x_test.tolist()]\n",
    "\n",
    "#train_y = [x[0].strip() for x in y_train.tolist()]\n",
    "#test_y = [x[0].strip() for x in y_test.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words= stop_words)), \n",
    "                     ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 0.5, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done 360 out of 360 | elapsed:  1.6min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'yours', 'from', 'had', 'hers', 'does', 'its', 'you', 'her', 'up', 'when', 'will', 'himself', 'some', 'there', 'our', 's', 'their', 'we', 'between', \"haven't\", 'doesn', 'themselves', \"weren't\", 'before', 'a', 'through', 'didn', 'same', 'the', \"mustn't\", 'being', \"hasn't\", 'off', 'him', '...ouldn't\", 'it', \"you've\", 'mightn', \"don't\", 'hasn', 'of', 't', \"doesn't\", 'yourself', 'she', 'but'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        47\n",
      "           1       0.88      0.88      0.88        17\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        64\n",
      "   macro avg       0.92      0.92      0.92        64\n",
      "weighted avg       0.94      0.94      0.94        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'))),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 0.4, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=2)]: Done 134 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=2)]: Done 294 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done 360 out of 360 | elapsed:  1.9min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'yours', 'from', 'had', 'hers', 'does', 'its', 'you', 'her', 'up', 'when', 'will', 'himself', 'some', 'there', 'our', 's', 'their', 'we', 'between', \"haven't\", 'doesn', 'themselves', \"weren't\", 'before', 'a', 'through', 'didn', 'same', 'the', \"mustn't\", 'being', \"hasn't\", 'off', 'him', '...ouldn't\", 'it', \"you've\", 'mightn', \"don't\", 'hasn', 'of', 't', \"doesn't\", 'yourself', 'she', 'but'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='sag', tol=0.0001, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        47\n",
      "           1       0.94      0.94      0.94        17\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        64\n",
      "   macro avg       0.96      0.96      0.96        64\n",
      "weighted avg       0.97      0.97      0.97        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(DecisionTreeClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__criterion\": ['gini', 'entropy'],\n",
    "    \"clf__estimator__splitter\": ['best', 'random'],\n",
    "    \"clf__estimator__max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=2)]: Done 137 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=2)]: Done 297 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done 521 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done 720 out of 720 | elapsed:  3.3min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'yours', 'from', 'had', 'hers', 'does', 'its', 'you', 'her', 'up', 'when', 'will', 'himself', 'some', 'there', 'our', 's', 'their', 'we', 'between', \"haven't\", 'doesn', 'themselves', \"weren't\", 'before', 'a', 'through', 'didn', 'same', 'the', \"mustn't\", 'being', \"hasn't\", 'off', 'him', '...ouldn't\", 'it', \"you've\", 'mightn', \"don't\", 'hasn', 'of', 't', \"doesn't\", 'yourself', 'she', 'but'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        47\n",
      "           1       0.89      1.00      0.94        17\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        64\n",
      "   macro avg       0.95      0.98      0.96        64\n",
      "weighted avg       0.97      0.97      0.97        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(KNeighborsClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__n_neighbors\": (2,3,4,5,6,7,8),\n",
    "    \"clf__estimator__weights\": ['uniform', 'distance'],\n",
    "    \"clf__estimator__algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 504 candidates, totalling 2520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  48 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=2)]: Done 145 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=2)]: Done 305 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done 529 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done 817 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=2)]: Done 1169 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=2)]: Done 1585 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=2)]: Done 2065 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=2)]: Done 2520 out of 2520 | elapsed: 11.5min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'yours', 'from', 'had', 'hers', 'does', 'its', 'you', 'her', 'up', 'when', 'will', 'himself', 'some', 'there', 'our', 's', 'their', 'we', 'between', \"haven't\", 'doesn', 'themselves', \"weren't\", 'before', 'a', 'through', 'didn', 'same', 'the', \"mustn't\", 'being', \"hasn't\", 'off', 'him', '...ouldn't\", 'it', \"you've\", 'mightn', \"don't\", 'hasn', 'of', 't', \"doesn't\", 'yourself', 'she', 'but'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
      "           weights='uniform'),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        47\n",
      "           1       0.74      0.82      0.78        17\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        64\n",
      "   macro avg       0.84      0.86      0.85        64\n",
      "weighted avg       0.88      0.88      0.88        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__criterion\": ['gini', 'entropy'],\n",
    "    \"clf__estimator__max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=2)]: Done 139 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=2)]: Done 299 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done 360 out of 360 | elapsed:  2.0min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'yours', 'from', 'had', 'hers', 'does', 'its', 'you', 'her', 'up', 'when', 'will', 'himself', 'some', 'there', 'our', 's', 'their', 'we', 'between', \"haven't\", 'doesn', 'themselves', \"weren't\", 'before', 'a', 'through', 'didn', 'same', 'the', \"mustn't\", 'being', \"hasn't\", 'off', 'him', '...ouldn't\", 'it', \"you've\", 'mightn', \"don't\", 'hasn', 'of', 't', \"doesn't\", 'yourself', 'she', 'but'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        47\n",
      "           1       1.00      0.71      0.83        17\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        64\n",
      "   macro avg       0.95      0.85      0.89        64\n",
      "weighted avg       0.93      0.92      0.92        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lda', LdaTransformer(num_topics=2, id2word=dictionary, iterations=14, random_state=17624)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC())),\n",
    "])\n",
    "parameters = {\n",
    "    'lda__num_topics': (2,3,4,5,6,7),\n",
    "    'lda__iterations': (14,15,16,17,18,19,20),\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 0.5, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 336 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=2)]: Done 1680 out of 1680 | elapsed:  4.3min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lda', LdaTransformer(alpha='symmetric', chunksize=2000, decay=0.5,\n",
      "        dtype=<class 'numpy.float32'>, eta=None, eval_every=10,\n",
      "        gamma_threshold=0.001,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207AF4EF518>,\n",
      "        iterations=14, minimum_probability=0.01, num_topics=2, offset=1.0,\n",
      "        passes=1, random_state=17624, scorer='perplexity', update_every=1)), ('clf', OneVsRestClassifier(estimator=LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        47\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        64\n",
      "   macro avg       0.37      0.50      0.42        64\n",
      "weighted avg       0.54      0.73      0.62        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lda', LdaTransformer(num_topics=2, id2word= dictionary, iterations=14, random_state=17624)),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'))),\n",
    "])\n",
    "parameters = {\n",
    "    'lda__num_topics': (2,3,4,5,6,7),\n",
    "    'lda__iterations': (14,15,16,17,18,19,20),\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 0.4, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 336 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=2)]: Done 1680 out of 1680 | elapsed:  3.9min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lda', LdaTransformer(alpha='symmetric', chunksize=2000, decay=0.5,\n",
      "        dtype=<class 'numpy.float32'>, eta=None, eval_every=10,\n",
      "        gamma_threshold=0.001,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207AF4BC550>,\n",
      "        iterations=14, minimum_probability=0.01, num_topics=2, offset=1.0,\n",
      "        passes=1, random_state=17624, scorer='perplexity', update_every=1)), ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
      "          tol=0.0001, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        47\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        64\n",
      "   macro avg       0.37      0.50      0.42        64\n",
      "weighted avg       0.54      0.73      0.62        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lda', LdaTransformer(num_topics=2, id2word= dictionary, iterations=14, random_state=17624)),\n",
    "    ('clf', OneVsRestClassifier(DecisionTreeClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'lda__num_topics': (2,3,4,5,6,7),\n",
    "    'lda__iterations': (14,15,16,17,18,19,20),\n",
    "    \"clf__estimator__criterion\": ['gini', 'entropy'],\n",
    "    \"clf__estimator__splitter\": ['best', 'random'],\n",
    "    \"clf__estimator__max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 672 candidates, totalling 3360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=2)]: Done 2588 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=2)]: Done 3360 out of 3360 | elapsed:  7.4min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lda', LdaTransformer(alpha='symmetric', chunksize=2000, decay=0.5,\n",
      "        dtype=<class 'numpy.float32'>, eta=None, eval_every=10,\n",
      "        gamma_threshold=0.001,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207AD703D68>,\n",
      "        iterations=17, minimum_probability=0.01, num_topics=6, offset=1.0,\n",
      "        passes=1, random_state=17624, scorer='perplexity', update_every=1)), ('clf', OneVsRestClassifier(estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        47\n",
      "           1       0.74      0.82      0.78        17\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        64\n",
      "   macro avg       0.84      0.86      0.85        64\n",
      "weighted avg       0.88      0.88      0.88        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lda', LdaTransformer(num_topics=2, id2word= dictionary, iterations=14, random_state=17624)),\n",
    "    ('clf', OneVsRestClassifier(KNeighborsClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'lda__num_topics': (2,3,4,5,6,7),\n",
    "    'lda__iterations': (14,15,16,17,18,19,20),\n",
    "    \"clf__estimator__n_neighbors\": (2,3,4,5,6,7,8),\n",
    "    \"clf__estimator__weights\": ['uniform', 'distance'],\n",
    "    \"clf__estimator__algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2352 candidates, totalling 11760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=2)]: Done 2588 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=2)]: Done 3868 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=2)]: Done 4604 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=2)]: Done 5404 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=2)]: Done 6268 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=2)]: Done 7196 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=2)]: Done 8188 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=2)]: Done 9244 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=2)]: Done 10364 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=2)]: Done 11548 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=2)]: Done 11760 out of 11760 | elapsed: 26.2min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lda', LdaTransformer(alpha='symmetric', chunksize=2000, decay=0.5,\n",
      "        dtype=<class 'numpy.float32'>, eta=None, eval_every=10,\n",
      "        gamma_threshold=0.001,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207AF775550>,\n",
      "        iterations=16, minimum_probability=0.01, num_topics=5, offset=1.0,\n",
      "        passes=1, random_state=17624, scorer='perplexity', update_every=1)), ('clf', OneVsRestClassifier(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
      "           weights='uniform'),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90        47\n",
      "           1       0.73      0.65      0.69        17\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        64\n",
      "   macro avg       0.81      0.78      0.79        64\n",
      "weighted avg       0.84      0.84      0.84        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lda', LdaTransformer(num_topics=2, id2word= dictionary, iterations=14, random_state=17624)),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'lda__num_topics': (2,3,4,5,6,7,8),\n",
    "    'lda__iterations': (14,15,16,17,18,19,20),\n",
    "    \"clf__estimator__criterion\": ['gini', 'entropy'],\n",
    "    \"clf__estimator__max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 392 candidates, totalling 1960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=2)]: Done 1960 out of 1960 | elapsed:  4.7min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lda', LdaTransformer(alpha='symmetric', chunksize=2000, decay=0.5,\n",
      "        dtype=<class 'numpy.float32'>, eta=None, eval_every=10,\n",
      "        gamma_threshold=0.001,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207ACAFF390>,\n",
      "        iterations=18, minimum_probability=0.01, num_topics=8, offset=1.0,\n",
      "        passes=1, random_state=17624, scorer='perplexity', update_every=1)), ('clf', OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        47\n",
      "           1       0.94      0.88      0.91        17\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        64\n",
      "   macro avg       0.95      0.93      0.94        64\n",
      "weighted avg       0.95      0.95      0.95        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('d2v', D2VTransformer(min_count=1, size=5)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC())),\n",
    "])\n",
    "parameters = {\n",
    "    'd2v__min_count': (1, 2,3,4,5,6,7,8,9,10),\n",
    "    'd2v__size': (5,6,7,8,9,10),\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 0.5, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=2)]: Done 2400 out of 2400 | elapsed: 24.7min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('d2v', D2VTransformer(alpha=0.025, batch_words=10000, cbow_mean=1, comment=None,\n",
      "        dbow_words=0, dm=1, dm_concat=0, dm_mean=None, dm_tag_count=1,\n",
      "        docvecs=None, docvecs_mapfile=None,\n",
      "        hashfxn=<built-in function hash>, hs=0, iter=5,\n",
      "        max_vocab_size=None, min_alpha=0.0001, min_count=1, negative=5,\n",
      "        sample=0.001, seed=1, size=6, sorted_vocab=1, trim_rule=None,\n",
      "        window=5, workers=3)), ('clf', OneVsRestClassifier(estimator=LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        47\n",
      "           1       1.00      0.82      0.90        17\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        64\n",
      "   macro avg       0.97      0.91      0.94        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(common_texts_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(common_texts_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('d2v', D2VTransformer(min_count=1, size=5)),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'))),\n",
    "])\n",
    "parameters = {\n",
    "    'd2v__min_count': (1, 2,3,4,5,6,7,8),\n",
    "    'd2v__size': (5,6,7,8,9,10),\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 0.4, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=2)]: Done 1920 out of 1920 | elapsed: 21.3min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('d2v', D2VTransformer(alpha=0.025, batch_words=10000, cbow_mean=1, comment=None,\n",
      "        dbow_words=0, dm=1, dm_concat=0, dm_mean=None, dm_tag_count=1,\n",
      "        docvecs=None, docvecs_mapfile=None,\n",
      "        hashfxn=<built-in function hash>, hs=0, iter=5,\n",
      "        max_vocab_size=None, min_alpha=0.0001, min_count=5, negative=5,\n",
      "        sample=0.001, seed=1, size=6, sorted_vocab=1, trim_rule=None,\n",
      "        window=5, workers=3)), ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=0.4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
      "          tol=0.0001, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        47\n",
      "           1       1.00      0.82      0.90        17\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        64\n",
      "   macro avg       0.97      0.91      0.94        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(common_texts_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(common_texts_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('d2v', D2VTransformer(min_count=1, size=5)),\n",
    "    ('clf', OneVsRestClassifier(DecisionTreeClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'd2v__min_count': (1, 2,3,4,5,6,7),\n",
    "    'd2v__size': (5,6,7,8,9,10),\n",
    "    \"clf__estimator__criterion\": ['gini', 'entropy'],\n",
    "    \"clf__estimator__splitter\": ['best', 'random'],\n",
    "    \"clf__estimator__max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 672 candidates, totalling 3360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=2)]: Done 2588 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=2)]: Done 3360 out of 3360 | elapsed: 37.9min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('d2v', D2VTransformer(alpha=0.025, batch_words=10000, cbow_mean=1, comment=None,\n",
      "        dbow_words=0, dm=1, dm_concat=0, dm_mean=None, dm_tag_count=1,\n",
      "        docvecs=None, docvecs_mapfile=None,\n",
      "        hashfxn=<built-in function hash>, hs=0, iter=5,\n",
      "        max_vocab_size=None, min_alpha=0.0001, min_count=1, negative=5,\n",
      "        sample=0.001, seed=1, size=10, sorted_vocab=1, trim_rule=None,\n",
      "        window=5, workers=3)), ('clf', OneVsRestClassifier(estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        47\n",
      "           1       1.00      0.82      0.90        17\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        64\n",
      "   macro avg       0.97      0.91      0.94        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(common_texts_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(common_texts_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('d2v', D2VTransformer(min_count=1, size=5)),\n",
    "    ('clf', OneVsRestClassifier(KNeighborsClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'd2v__min_count': (1, 2,3,4,5,6,7,8),\n",
    "    'd2v__size': (5,6,7,8,9,10),\n",
    "    \"clf__estimator__n_neighbors\": (2,3,4,5,6,7),\n",
    "    \"clf__estimator__weights\": ['uniform', 'distance'],\n",
    "    \"clf__estimator__algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=2)]: Done 2588 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=2)]: Done 3868 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=2)]: Done 4604 tasks      | elapsed: 51.5min\n",
      "[Parallel(n_jobs=2)]: Done 5404 tasks      | elapsed: 60.1min\n",
      "[Parallel(n_jobs=2)]: Done 6268 tasks      | elapsed: 69.1min\n",
      "[Parallel(n_jobs=2)]: Done 7196 tasks      | elapsed: 78.7min\n",
      "[Parallel(n_jobs=2)]: Done 8188 tasks      | elapsed: 89.5min\n",
      "[Parallel(n_jobs=2)]: Done 9244 tasks      | elapsed: 101.1min\n",
      "[Parallel(n_jobs=2)]: Done 10364 tasks      | elapsed: 112.9min\n",
      "[Parallel(n_jobs=2)]: Done 11520 out of 11520 | elapsed: 126.0min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('d2v', D2VTransformer(alpha=0.025, batch_words=10000, cbow_mean=1, comment=None,\n",
      "        dbow_words=0, dm=1, dm_concat=0, dm_mean=None, dm_tag_count=1,\n",
      "        docvecs=None, docvecs_mapfile=None,\n",
      "        hashfxn=<built-in function hash>, hs=0, iter=5,\n",
      "        max_vocab_size=None, min_alpha=0.0001, min_count=2, negative=5,\n",
      "        sample=0.001, seed=1, size=7, sorted_vocab=1, trim_rule=None,\n",
      "        window=5, workers=3)), ('clf', OneVsRestClassifier(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
      "           weights='uniform'),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        47\n",
      "           1       1.00      0.82      0.90        17\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        64\n",
      "   macro avg       0.97      0.91      0.94        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(common_texts_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(common_texts_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('d2v', D2VTransformer(min_count=1, size=5)),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'd2v__min_count': (1, 2,3,4,5,6,7,8,9,10),\n",
    "    'd2v__size': (5,6,7,8,9,10),\n",
    "    \"clf__estimator__criterion\": ['gini', 'entropy'],\n",
    "    \"clf__estimator__max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=2)]: Done 2400 out of 2400 | elapsed: 26.0min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('d2v', D2VTransformer(alpha=0.025, batch_words=10000, cbow_mean=1, comment=None,\n",
      "        dbow_words=0, dm=1, dm_concat=0, dm_mean=None, dm_tag_count=1,\n",
      "        docvecs=None, docvecs_mapfile=None,\n",
      "        hashfxn=<built-in function hash>, hs=0, iter=5,\n",
      "        max_vocab_size=None, min_alpha=0.0001, min_count=2, negative=5,\n",
      "        sample=0.001, seed=1, size=7, sorted_vocab=1, trim_rule=None,\n",
      "        window=5, workers=3)), ('clf', OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        47\n",
      "           1       1.00      0.82      0.90        17\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        64\n",
      "   macro avg       0.97      0.91      0.94        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(common_texts_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(common_texts_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lsa', LsiTransformer(num_topics=2, id2word= dictionary)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC())),\n",
    "])\n",
    "parameters = {\n",
    "    'lsa__num_topics': (2,3,4,5,6,7),\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 0.5, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=2)]: Done 240 out of 240 | elapsed:   25.7s finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lsa', LsiTransformer(chunksize=20000, decay=1.0, extra_samples=100,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207AD11AB00>,\n",
      "        num_topics=3, onepass=True, power_iters=2)), ('clf', OneVsRestClassifier(estimator=LinearSVC(C=0.1, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        47\n",
      "           1       0.88      0.82      0.85        17\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        64\n",
      "   macro avg       0.91      0.89      0.90        64\n",
      "weighted avg       0.92      0.92      0.92        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lsa', LsiTransformer(num_topics=2, id2word= dictionary)),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'))),\n",
    "])\n",
    "parameters = {\n",
    "    'lsa__num_topics': (2,3,4,5,6,7),\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 0.4, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=2)]: Done 240 out of 240 | elapsed:   25.8s finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lsa', LsiTransformer(chunksize=20000, decay=1.0, extra_samples=100,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207AF896320>,\n",
      "        num_topics=7, onepass=True, power_iters=2)), ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
      "          tol=0.0001, verbose=0, warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87        47\n",
      "           1       0.62      0.94      0.74        17\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        64\n",
      "   macro avg       0.79      0.86      0.81        64\n",
      "weighted avg       0.88      0.83      0.84        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lsa', LsiTransformer(num_topics=2, id2word= dictionary)),\n",
    "    ('clf', OneVsRestClassifier(DecisionTreeClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'lsa__num_topics': (2,3,4,5,6,7),\n",
    "    \"clf__estimator__criterion\": ['gini', 'entropy'],\n",
    "    \"clf__estimator__splitter\": ['best', 'random'],\n",
    "    \"clf__estimator__max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=2)]: Done 480 out of 480 | elapsed:   50.7s finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lsa', LsiTransformer(chunksize=20000, decay=1.0, extra_samples=100,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207AF158B00>,\n",
      "        num_topics=2, onepass=True, power_iters=2)), ('clf', OneVsRestClassifier(estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random'),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        47\n",
      "           1       0.93      0.76      0.84        17\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        64\n",
      "   macro avg       0.92      0.87      0.89        64\n",
      "weighted avg       0.92      0.92      0.92        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lsa', LsiTransformer(num_topics=2, id2word= dictionary)),\n",
    "    ('clf', OneVsRestClassifier(KNeighborsClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'lsa__num_topics': (2,3,4,5,6,7),\n",
    "    \"clf__estimator__n_neighbors\": (2,3,4,5,6,7),\n",
    "    \"clf__estimator__weights\": ['uniform', 'distance'],\n",
    "    \"clf__estimator__algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=2)]: Done 1440 out of 1440 | elapsed:  2.6min finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lsa', LsiTransformer(chunksize=20000, decay=1.0, extra_samples=100,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207AFAF4898>,\n",
      "        num_topics=7, onepass=True, power_iters=2)), ('clf', OneVsRestClassifier(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
      "           weights='distance'),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        47\n",
      "           1       0.94      0.94      0.94        17\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        64\n",
      "   macro avg       0.96      0.96      0.96        64\n",
      "weighted avg       0.97      0.97      0.97        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lsa', LsiTransformer(num_topics=2, id2word= dictionary)),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier())),\n",
    "])\n",
    "parameters = {\n",
    "    'lsa__num_topics': (2,3,4,5,6,7),\n",
    "    \"clf__estimator__criterion\": ['gini', 'entropy'],\n",
    "    \"clf__estimator__max_features\": ['auto', 'sqrt', 'log2', None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  52 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=2)]: Done 240 out of 240 | elapsed:   15.4s finished\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Djordje\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('lsa', LsiTransformer(chunksize=20000, decay=1.0, extra_samples=100,\n",
      "        id2word=<gensim.corpora.dictionary.Dictionary object at 0x00000207ACFB04E0>,\n",
      "        num_topics=5, onepass=True, power_iters=2)), ('clf', OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "          n_jobs=None))]\n",
      "Applying best classifier on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        47\n",
      "           1       0.93      0.82      0.87        17\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        64\n",
      "   macro avg       0.94      0.90      0.92        64\n",
      "weighted avg       0.94      0.94      0.94        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_x = map(int, train_x)\n",
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline, parameters, cv=5, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(bow_train, y_train)\n",
    "\n",
    "print\n",
    "print(\"Best parameters set:\")\n",
    "print (grid_search_tune.best_estimator_.steps)\n",
    "print\n",
    "\n",
    "# measuring performance on test set\n",
    "print (\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(bow_test)\n",
    "\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
